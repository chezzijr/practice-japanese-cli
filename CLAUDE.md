# Japanese Learning CLI - Project Context

This document provides comprehensive context about the Japanese Learning CLI project for Claude Code to understand the architecture, conventions, and implementation details.

## Project Overview

**Purpose**: A CLI-based Japanese learning tool designed for Vietnamese learners, featuring intelligent spaced repetition (FSRS), progress tracking, and comprehensive vocabulary/kanji/grammar management.

**Target User**: Vietnamese speakers learning Japanese (currently studying N4, started with N5 data import)

**Core Philosophy**:
- Offline-first with local SQLite storage
- Keyboard-driven CLI workflow for efficiency
- Beautiful terminal UI using Rich
- FSRS algorithm for scientifically-backed spaced repetition
- Support for Sino-Vietnamese readings to leverage Vietnamese learners' advantage

## Technology Stack

- **Language**: Python 3.10+
- **Package Manager**: uv (modern, fast Python package manager)
- **CLI Framework**: Typer (command structure) + Rich (terminal rendering)
- **Database**: SQLite3 with JSON fields for complex data
- **SRS Algorithm**: py-fsrs (official FSRS implementation from PyPI)
- **Data Sources**: JMdict (vocabulary) and KANJIDIC2 (kanji) from EDRDG
- **Data Validation**: Pydantic v2

## Project Structure

```
practice-japanese-cli/
‚îú‚îÄ‚îÄ README.md                  # User-facing documentation
‚îú‚îÄ‚îÄ CLAUDE.md                  # This file - project context for Claude Code
‚îú‚îÄ‚îÄ PLAN.md                    # Implementation roadmap
‚îú‚îÄ‚îÄ pyproject.toml             # uv project config and dependencies
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ japanese_cli/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ main.py            # Typer app entry point, command registration
‚îÇ       ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ models/            # Pydantic models and dataclasses
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ vocabulary.py  # Vocabulary model with readings, meanings
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ kanji.py       # Kanji model with on/kun readings
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ grammar.py     # Grammar point model with examples
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ review.py      # Review session and card state models
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ progress.py    # Progress tracking models
‚îÇ       ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ database/          # Database layer
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ connection.py  # SQLite connection management, context managers
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ schema.py      # CREATE TABLE statements, migrations
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ queries.py     # Reusable query functions (CRUD operations)
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ migrations.py  # Database version management
‚îÇ       ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ srs/               # Spaced repetition system
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ fsrs.py        # Wrapper around py-fsrs library
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ scheduler.py   # Review scheduling logic, due card queries
‚îÇ       ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ importers/         # Data import from external sources
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ jmdict.py      # JMdict XML parser for vocabulary
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ kanjidic.py    # KANJIDIC2 XML parser for kanji
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ jlpt.py        # JLPT level mapping (from external lists)
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ custom.py      # CSV/JSON custom import
‚îÇ       ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ cli/               # Command implementations
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ flashcard.py   # flashcard add/review/list/edit commands
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ progress.py    # progress show/set-level/stats commands
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ grammar.py     # grammar add/list/show commands
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ import_data.py # import n5/custom commands
‚îÇ       ‚îÇ
‚îÇ       ‚îî‚îÄ‚îÄ ui/                # Rich UI components and formatters
‚îÇ           ‚îú‚îÄ‚îÄ __init__.py
‚îÇ           ‚îú‚îÄ‚îÄ display.py     # Rich Panel, Table, Text formatters
‚îÇ           ‚îú‚îÄ‚îÄ furigana.py    # Furigana rendering logic
‚îÇ           ‚îî‚îÄ‚îÄ prompts.py     # Interactive input prompts
‚îÇ
‚îú‚îÄ‚îÄ data/                      # Runtime data (gitignored except .gitkeep)
‚îÇ   ‚îú‚îÄ‚îÄ .gitkeep
‚îÇ   ‚îú‚îÄ‚îÄ japanese.db            # SQLite database file
‚îÇ   ‚îî‚îÄ‚îÄ dict/                  # Downloaded JMdict/KANJIDIC2 files
‚îÇ       ‚îî‚îÄ‚îÄ .gitkeep
‚îÇ
‚îî‚îÄ‚îÄ tests/                     # Unit tests (pytest)
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ test_models.py
    ‚îú‚îÄ‚îÄ test_database.py
    ‚îú‚îÄ‚îÄ test_srs.py
    ‚îî‚îÄ‚îÄ test_importers.py
```

## Database Schema

### Table: `vocabulary`
Stores Japanese vocabulary words with readings and meanings.

```sql
CREATE TABLE vocabulary (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    word TEXT NOT NULL,                    -- Kanji/kana form (e.g., "ÂçòË™û")
    reading TEXT NOT NULL,                 -- Hiragana/katakana (e.g., "„Åü„Çì„Åî")
    meanings TEXT NOT NULL,                -- JSON: {"vi": ["t·ª´ v·ª±ng"], "en": ["word", "vocabulary"]}
    vietnamese_reading TEXT,               -- Sino-Vietnamese reading (e.g., "ƒë∆°n ng·ªØ")
    jlpt_level TEXT,                       -- n5, n4, n3, n2, n1, or NULL
    part_of_speech TEXT,                   -- noun, verb, adjective, etc.
    tags TEXT,                             -- JSON array: ["common", "beginner-friendly"]
    notes TEXT,                            -- User notes
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

**Indexes**:
- `idx_vocabulary_jlpt` on `jlpt_level`
- `idx_vocabulary_word` on `word`

### Table: `kanji`
Stores individual kanji characters with readings and meanings.

```sql
CREATE TABLE kanji (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    character TEXT NOT NULL UNIQUE,        -- Single kanji (e.g., "Ë™û")
    on_readings TEXT NOT NULL,             -- JSON array: ["„Ç¥"]
    kun_readings TEXT NOT NULL,            -- JSON array: ["„Åã„Åü.„Çã", "„Åã„Åü.„Çâ„ÅÜ"]
    meanings TEXT NOT NULL,                -- JSON: {"vi": ["ng·ªØ"], "en": ["word", "language"]}
    vietnamese_reading TEXT,               -- H√°n Vi·ªát (e.g., "ng·ªØ")
    jlpt_level TEXT,                       -- n5, n4, n3, n2, n1, or NULL
    stroke_count INTEGER,
    radical TEXT,                          -- Radical character
    notes TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

**Indexes**:
- `idx_kanji_jlpt` on `jlpt_level`
- `idx_kanji_character` on `character` (automatically created with UNIQUE)

### Table: `grammar_points`
Stores grammar explanations with examples.

```sql
CREATE TABLE grammar_points (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    title TEXT NOT NULL,                   -- e.g., "„ÅØ (wa) particle"
    structure TEXT,                        -- Grammar structure pattern
    explanation TEXT NOT NULL,             -- Vietnamese/English explanation
    jlpt_level TEXT,
    examples TEXT NOT NULL,                -- JSON array of {"jp": "...", "vi": "...", "en": "..."}
    related_grammar TEXT,                  -- JSON array of related grammar IDs
    notes TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

**Indexes**:
- `idx_grammar_jlpt` on `jlpt_level`

### Table: `reviews`
Tracks FSRS state for each flashcard (vocabulary or kanji).

```sql
CREATE TABLE reviews (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    item_id INTEGER NOT NULL,              -- Foreign key to vocabulary.id or kanji.id
    item_type TEXT NOT NULL,               -- 'vocab' or 'kanji'
    fsrs_card_state TEXT NOT NULL,         -- JSON: FSRS Card state (difficulty, stability, etc.)
    due_date TIMESTAMP NOT NULL,           -- Next review date
    last_reviewed TIMESTAMP,               -- Last review timestamp
    review_count INTEGER DEFAULT 0,        -- Total reviews done
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(item_id, item_type)
);
```

**Indexes**:
- `idx_reviews_due` on `due_date`
- `idx_reviews_item` on `(item_id, item_type)`

### Table: `review_history`
Complete history of all reviews for analytics and progress tracking.

```sql
CREATE TABLE review_history (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    review_id INTEGER NOT NULL,            -- Foreign key to reviews.id
    rating INTEGER NOT NULL,               -- FSRS rating: 1 (Again), 2 (Hard), 3 (Good), 4 (Easy)
    duration_ms INTEGER,                   -- Time spent reviewing (milliseconds)
    reviewed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (review_id) REFERENCES reviews(id) ON DELETE CASCADE
);
```

**Indexes**:
- `idx_history_review` on `review_id`
- `idx_history_date` on `reviewed_at`

### Table: `progress`
User progress tracking and statistics.

```sql
CREATE TABLE progress (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    user_id TEXT DEFAULT 'default',        -- Multi-user support (future)
    current_level TEXT DEFAULT 'n5',       -- Current studying level
    target_level TEXT DEFAULT 'n5',        -- Target JLPT level
    stats TEXT NOT NULL,                   -- JSON: detailed statistics
    milestones TEXT,                       -- JSON: achieved milestones
    streak_days INTEGER DEFAULT 0,
    last_review_date DATE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(user_id)
);
```

**Stats JSON structure**:
```json
{
  "total_vocab": 500,
  "total_kanji": 103,
  "mastered_vocab": 50,
  "mastered_kanji": 20,
  "total_reviews": 1000,
  "average_retention": 0.85
}
```

## FSRS Integration

### py-fsrs Library Usage (v6.3.0+)
```python
from fsrs import Scheduler, Card, Rating, ReviewLog, State
from datetime import datetime, timezone

# Initialize scheduler (default parameters)
scheduler = Scheduler()

# Create a new card
card = Card()

# Review a card with a rating
rating = Rating.Good  # Or: Rating.Again, Rating.Hard, Rating.Good, Rating.Easy
card, review_log = scheduler.review_card(card, rating)

# The card object is now updated with new FSRS state
# review_log contains information about this review session

# Store card state as JSON in database using built-in serialization
card_state_json = card.to_dict()
# Returns: {
#     "card_id": int,
#     "state": int,  # 1=Learning, 2=Review, 3=Relearning
#     "step": int,
#     "stability": float | None,
#     "difficulty": float | None,
#     "due": "ISO datetime string",
#     "last_review": "ISO datetime string" | None
# }

# Restore card from database
card = Card.from_dict(card_state_json)

# Custom scheduler parameters (optional)
from datetime import timedelta
scheduler = Scheduler(
    desired_retention=0.9,  # 90% retention rate
    learning_steps=(timedelta(minutes=1), timedelta(minutes=10)),
    relearning_steps=(timedelta(minutes=10),),
    maximum_interval=36500,  # days
    enable_fuzzing=True
)
```

### Rating System
- `Rating.Again` (1): Forgot the card, review soon
- `Rating.Hard` (2): Difficult to recall, shorter interval
- `Rating.Good` (3): Recalled correctly, normal interval
- `Rating.Easy` (4): Very easy to recall, longer interval

## UI/UX Design

### Furigana Display
Format kanji with furigana using Rich markup:
- Format: `ÂçòË™û[„Åü„Çì„Åî]` displayed as kanji with reading
- Use Rich Text with different colors for kanji vs. furigana

```python
from rich.text import Text

def format_with_furigana(word: str, reading: str) -> Text:
    text = Text()
    text.append(word, style="bold cyan")
    text.append(f"[{reading}]", style="dim cyan")
    return text
```

### Review Session Flow
1. Show card front (e.g., Vietnamese meaning)
2. User presses Enter to reveal answer
3. Show card back (Japanese word with furigana, readings)
4. User rates: 1 (Again), 2 (Hard), 3 (Good), 4 (Easy)
5. Update FSRS state and move to next card
6. Display progress bar and session statistics

### Rich Components
- **Panels**: For card display, statistics dashboard
- **Tables**: For listing vocabulary/kanji/grammar
- **Progress bars**: For review sessions, import progress
- **Prompts**: Using rich.prompt for interactive input

## Coding Conventions

### Python Style
- Follow PEP 8
- Use type hints for all function signatures
- Use Pydantic models for data validation
- Use `snake_case` for functions and variables
- Use `PascalCase` for classes

### Database Access
- Use context managers for database connections
- Parameterized queries (no string interpolation)
- Transaction management for related writes
- Handle errors gracefully with try/except

```python
from contextlib import contextmanager

@contextmanager
def get_db_connection():
    conn = sqlite3.connect("data/japanese.db")
    conn.row_factory = sqlite3.Row
    try:
        yield conn
        conn.commit()
    except Exception:
        conn.rollback()
        raise
    finally:
        conn.close()
```

### CLI Command Structure
- Each command group in separate file (cli/flashcard.py, cli/progress.py, etc.)
- Use Typer app instances
- Provide helpful error messages
- Use Rich for all output (no plain print())

### Error Handling
- Use custom exceptions for domain errors
- Display user-friendly error messages using Rich Console
- Log errors for debugging (future: add logging module)

## Data Import Strategy

### JMdict Vocabulary Import
1. Download JMdict_e.gz from EDRDG
2. Parse XML using lxml
3. Filter by JLPT level (using external N5 word list)
4. Extract word, readings, meanings (English)
5. Store in database with JLPT level tag

### KANJIDIC2 Kanji Import
1. Download kanjidic2.xml.gz from EDRDG
2. Parse XML for each kanji
3. Extract on-readings, kun-readings, meanings, stroke count
4. Filter by JLPT level (using external N5 kanji list)
5. Store in database

### Vietnamese Reading Handling
- Vietnamese readings (H√°n Vi·ªát) are not in JMdict/KANJIDIC2
- Initially support manual entry via CLI
- Future: integrate H√°n Vi·ªát dictionary or conversion system
- For kanji, Sino-Vietnamese readings often correlate with on-yomi

### JLPT Level Mapping
- JMdict/KANJIDIC2 don't tag JLPT levels officially
- Use external sources:
  - tanos.co.uk JLPT lists (CSV format)
  - jlptsensei.com lists
  - Jonathan Waller's JLPT resources
- Cross-reference by word/kanji to assign levels

## Testing Strategy

### Overview
- Write tests after completing each phase (before moving to next phase)
- Target 80%+ code coverage per module
- Use pytest for all testing
- Both positive (happy path) and negative (error handling) test cases

### Test Structure
```
tests/
‚îú‚îÄ‚îÄ conftest.py              # Shared fixtures
‚îú‚îÄ‚îÄ test_connection.py       # Database connection tests
‚îú‚îÄ‚îÄ test_schema.py          # Schema validation tests
‚îú‚îÄ‚îÄ test_migrations.py      # Migration system tests
‚îú‚îÄ‚îÄ test_queries.py         # CRUD operation tests
‚îî‚îÄ‚îÄ test_fsrs_integration.py # FSRS integration tests
```

### Running Tests
```bash
# Run all tests with verbose output
uv run pytest -v

# Run with coverage report
uv run pytest --cov=src/japanese_cli --cov-report=term-missing

# Run specific test file
uv run pytest tests/test_queries.py -v

# Run specific test
uv run pytest tests/test_queries.py::test_add_vocabulary_success -v
```

### Test Fixtures (conftest.py)
- `temp_db_path` - Temporary database file path
- `clean_db` - Fresh initialized database with progress
- `sample_vocabulary` - Sample vocabulary data dictionary
- `sample_kanji` - Sample kanji data dictionary
- `sample_grammar` - Sample grammar data dictionary
- `db_with_vocabulary` - Database with sample vocabulary inserted
- `db_with_kanji` - Database with sample kanji inserted
- `db_with_review` - Database with vocabulary and review entry

### Test Categories

**Unit Tests**: Test individual functions in isolation
- Database queries (CRUD operations)
- FSRS card serialization
- Schema validation
- Migration functions

**Integration Tests**: Test components working together
- Review workflow (create ‚Üí review ‚Üí update ‚Üí history)
- Database initialization process
- FSRS scheduler with database persistence

**Positive Tests**: Verify correct behavior
- Adding vocabulary/kanji/grammar
- Retrieving data by ID
- Listing with filters
- Searching by terms

**Negative Tests**: Verify error handling
- Non-existent IDs return None
- Duplicate entries raise IntegrityError
- Foreign key constraints enforced
- Invalid inputs handled gracefully

**Edge Cases**: Test boundary conditions
- Empty databases
- Large result sets (pagination)
- Missing optional fields
- Concurrent access (transactions)

### Current Test Coverage (Phase 2)
- **76 tests total**, all passing
- **80% code coverage** on database module
- Test files:
  - `test_connection.py` - 8 tests
  - `test_schema.py` - 9 tests
  - `test_migrations.py` - 9 tests
  - `test_queries.py` - 40 tests
  - `test_fsrs_integration.py` - 10 tests

### Testing Best Practices
1. **Isolation**: Each test uses a fresh temporary database
2. **Descriptive names**: `test_function_name_expected_behavior`
3. **Arrange-Act-Assert**: Clear test structure
4. **One assertion focus**: Test one thing per test when possible
5. **Fixtures for reuse**: Common test data in conftest.py
6. **Fast tests**: All tests complete in < 1 second total

## Future Enhancements

### Nearest Neighbor Clustering
- Use embeddings (sentence-transformers) to group similar vocabulary
- Display related words together in review sessions
- Help learners build thematic vocabulary clusters

### AI/LLM Integration (MCP)
- Use Claude/GPT via MCP for:
  - Personalized study recommendations
  - Conversation practice
  - Exercise generation based on JLPT level
  - Knowledge assessment (what user knows vs. needs to learn)
  - Auto-populate database from user's study materials

### Enhanced Progress Tracking
- Heatmap calendar of review activity
- Retention rate graphs by JLPT level
- Predicted time to mastery for each level
- Comparison with typical learning curves

## Important Implementation Notes

1. **Database Location**: Store `japanese.db` in `data/` directory, create if not exists
2. **FSRS Parameters**: Use default parameters initially, allow customization later
3. **Date Handling**: Store all timestamps in UTC, display in local time
4. **Vietnamese Input**: Ensure terminal supports Vietnamese characters (UTF-8)
5. **Large Imports**: Show progress bars for N5 import (800+ words, 103 kanji)
6. **Testing Data**: Provide sample vocabulary/kanji for quick testing without full import

## Key Dependencies

```toml
[project]
requires-python = ">=3.10"
dependencies = [
    "typer[all]>=0.9.0",      # CLI framework with rich support
    "rich>=13.0.0",           # Terminal formatting
    "fsrs>=4.0.0",            # FSRS algorithm
    "requests>=2.31.0",       # HTTP downloads
    "lxml>=4.9.0",            # XML parsing
    "python-dateutil>=2.8.0", # Date utilities
    "pydantic>=2.0.0",        # Data validation
]
```

## Common Commands Reference

```bash
# Initialize database (first run)
japanese-cli init

# Add vocabulary manually
japanese-cli flashcard add --type vocab

# Add kanji manually
japanese-cli flashcard add --type kanji

# Import N5 data (both vocab and kanji)
japanese-cli import n5 --vocab --kanji

# Review due cards
japanese-cli flashcard review

# Review specific level
japanese-cli flashcard review --level n5 --limit 20

# View progress
japanese-cli progress show

# View detailed stats
japanese-cli progress stats --range 30d
```

## Development Workflow

1. Make changes in `src/japanese_cli/`
2. Test locally: `uv run japanese-cli <command>`
3. Run tests: `uv run pytest`
4. Commit with descriptive messages
5. Update PLAN.md to track implementation progress

## Questions to Consider

When implementing features, consider:
- How will this scale with thousands of vocabulary words?
- Is the UX intuitive for CLI users?
- Are error messages clear and actionable?
- Does this work well for Vietnamese learners specifically?
- How will this feature integrate with future AI capabilities?

---

## Current Implementation Status

**Phase 1: Project Setup & Documentation** - ‚úÖ COMPLETE (2025-10-26)

### Completed:
- ‚úÖ README.md with comprehensive user documentation
- ‚úÖ CLAUDE.md with full project context and architecture (updated with FSRS 6.3.0 API)
- ‚úÖ PLAN.md with detailed 10-phase implementation roadmap
- ‚úÖ pyproject.toml configured with all dependencies
- ‚úÖ Complete project structure (src/japanese_cli/ with all module directories)
- ‚úÖ Basic CLI entry point (`japanese-cli` command)
- ‚úÖ Git repository initialized with proper .gitignore
- ‚úÖ All dependencies installed and verified (fsrs 6.3.0, typer 0.20.0, rich 14.2.0, etc.)

**Phase 2: Database Layer** - ‚úÖ COMPLETE (2025-10-26)

### Completed:
- ‚úÖ Database schema (database/schema.py) - 6 tables with 8 indexes
- ‚úÖ Connection management (database/connection.py) - context managers, transactions
- ‚úÖ Migration system (database/migrations.py) - PRAGMA user_version tracking
- ‚úÖ Query utilities (database/queries.py) - full CRUD for all models
- ‚úÖ Database __init__.py - exports all key functions
- ‚úÖ Functional `init` command - creates DB, runs migrations, initializes progress
- ‚úÖ FSRS integration verified - Card serialization, review scheduling tested

### Database Tables:
- `vocabulary` - Japanese words with readings, meanings, JLPT levels
- `kanji` - Kanji characters with on/kun readings, Vietnamese readings
- `grammar_points` - Grammar explanations with examples
- `reviews` - FSRS card state for each flashcard
- `review_history` - Complete review history for analytics
- `progress` - User progress tracking and statistics

### Working Commands:
```bash
uv run japanese-cli --help    # Show available commands
uv run japanese-cli version   # Show version information
uv run japanese-cli init      # Initialize database (fully functional!)
```

### Verified Features:
- ‚úÖ Database creation at `data/japanese.db`
- ‚úÖ Schema migrations with version tracking
- ‚úÖ CRUD operations for vocabulary and kanji
- ‚úÖ FSRS Card state persistence (using Card.to_dict() / Card.from_dict())
- ‚úÖ Review scheduling and due card queries
- ‚úÖ Progress initialization and tracking
- ‚úÖ Idempotent init command (safe to run multiple times)

**Phase 3: Data Models** - ‚úÖ COMPLETE (2025-10-26)

### Completed:
- ‚úÖ Pydantic v2 models for all entities (Vocabulary, Kanji, GrammarPoint, Review, Progress)
- ‚úÖ Field validators for JLPT levels, ratings, character lengths
- ‚úÖ Model validators for cross-field validation
- ‚úÖ Database conversion methods (from_db_row, to_db_dict)
- ‚úÖ JSON field serialization/deserialization
- ‚úÖ FSRS Card integration in Review model
- ‚úÖ Nested models (Example, ProgressStats)
- ‚úÖ Enum support (ItemType)
- ‚úÖ 40 comprehensive tests, 92% coverage

### Models Available:
```python
from japanese_cli.models import (
    Vocabulary,
    Kanji,
    Example,
    GrammarPoint,
    ItemType,
    Review,
    ReviewHistory,
    Progress,
    ProgressStats
)
```

**Phase 4: FSRS Integration** - ‚úÖ COMPLETE (2025-10-26)

### Completed:
- ‚úÖ FSRSManager class (srs/fsrs.py) - FSRS wrapper with configurable parameters
- ‚úÖ ReviewScheduler class (srs/scheduler.py) - high-level review coordinator
- ‚úÖ Rating conversion utilities (int ‚Üî Rating enum)
- ‚úÖ Full review workflow: create ‚Üí review ‚Üí update ‚Üí history
- ‚úÖ Filtering by JLPT level, item type, and limit
- ‚úÖ Review statistics and counting methods
- ‚úÖ 37 comprehensive tests, 94% coverage

### SRS API Available:
```python
from japanese_cli.srs import FSRSManager, ReviewScheduler

# Create scheduler (uses default FSRS parameters)
scheduler = ReviewScheduler()

# Custom FSRS configuration
custom_fsrs = FSRSManager(desired_retention=0.95)
scheduler = ReviewScheduler(fsrs_manager=custom_fsrs)

# Create review for vocabulary/kanji
review_id = scheduler.create_new_review(vocab_id, ItemType.VOCAB)

# Get due reviews with filters
due_reviews = scheduler.get_due_reviews(limit=20, jlpt_level='n5')

# Process review (complete workflow)
updated_review = scheduler.process_review(
    review_id=review_id,
    rating=3,  # Good
    duration_ms=5000
)

# Get review statistics
total_reviews = scheduler.get_review_count()
n5_vocab_reviews = scheduler.get_review_count(jlpt_level='n5', item_type=ItemType.VOCAB)
```

### Key Features:
- Simple API for CLI layer - no manual FSRS Card management needed
- Automatic database persistence and transaction handling
- Review history automatically recorded
- Comprehensive error handling (invalid items, ratings)
- Full type hints and documentation
- Reuses existing database layer (thin wrapper)

**Phase 5: Data Import System** - ‚úÖ COMPLETE (2025-10-26)

### Completed:
- ‚úÖ JLPTLevelMapper class (importers/jlpt.py) - 174 lines, 98% coverage
- ‚úÖ JMdictImporter class (importers/jmdict.py) - 299 lines, streaming XML parser
- ‚úÖ KanjidicImporter class (importers/kanjidic.py) - 293 lines, streaming XML parser
- ‚úÖ Import utilities (importers/utils.py) - 193 lines, download/decompress/POS mapping
- ‚úÖ CLI import commands (cli/import_data.py) - 146 lines
- ‚úÖ JLPT reference files - n5_vocab.csv (81 words), n5_kanji.txt (103 chars)
- ‚úÖ Sample XML fixtures for testing (JMdict and KANJIDIC2)
- ‚úÖ 23 comprehensive tests (17 JLPT mapper, 6 integration)

### Import Commands Available:
```bash
japanese-cli import n5              # Import both vocab and kanji
japanese-cli import n5 --vocab      # Import vocabulary only
japanese-cli import n5 --kanji      # Import kanji only
japanese-cli import n5 --force      # Force re-download data files
```

### Key Features:
- **Streaming XML parsing** with lxml.etree.iterparse() for memory efficiency
- **Rich progress bars** for download, parsing, and database operations
- **Duplicate detection** with smart update logic
- **JLPT N5 filtering** using manual reference lists
- **Error handling** with retry logic for downloads
- **Part of speech mapping** from JMdict entities

**Phase 6: Flashcard CLI - Add & List** - ‚úÖ COMPLETE (2025-10-26)

### Completed:
- ‚úÖ UI utilities - 813 lines total
  - ui/furigana.py (135 lines) - Furigana rendering with compact/detailed styles
  - ui/display.py (352 lines) - Rich tables and panels for vocab/kanji
  - ui/prompts.py (282 lines) - Interactive data collection with validation
  - ui/__init__.py (44 lines) - Clean exports
- ‚úÖ Flashcard CLI (cli/flashcard.py) - 453 lines with 4 commands
- ‚úÖ Manual end-to-end testing with real N5 data (81 vocab, 103 kanji)
- ‚úÖ Comprehensive test suite - 106 tests with 97% coverage on UI modules
  - test_ui_furigana.py (23 tests) - 100% coverage on furigana.py
  - test_ui_display.py (29 tests) - 99% coverage on display.py
  - test_ui_prompts.py (25 tests) - 93% coverage on prompts.py
  - test_flashcard_cli.py (29 tests) - 79% coverage on flashcard.py

### Flashcard Commands Available:
```bash
# List flashcards
japanese-cli flashcard list --type vocab                 # All vocabulary
japanese-cli flashcard list --type kanji --level n5      # N5 kanji only
japanese-cli flashcard list --type vocab --limit 20      # Show 20 items

# Show detailed view
japanese-cli flashcard show 75 --type vocab              # Detailed vocab view
japanese-cli flashcard show 1 --type kanji               # Detailed kanji view

# Add new flashcards (interactive)
japanese-cli flashcard add --type vocab                  # Add vocabulary
japanese-cli flashcard add --type kanji                  # Add kanji

# Edit existing flashcards (interactive)
japanese-cli flashcard edit 75 --type vocab              # Edit vocab
japanese-cli flashcard edit 1 --type kanji               # Edit kanji
```

### Key Features:
- **Rich UI components** - Beautiful tables with furigana: ÂçòË™û[„Åü„Çì„Åî]
- **JLPT color coding** - n5=green, n4=cyan, n3=yellow, n2=magenta, n1=red
- **Interactive prompts** - Pydantic validation at input time
- **Review integration** - Display due dates, auto-add to review queue
- **Vietnamese support** - UTF-8 encoding, Vietnamese priority in displays
- **Flexible filtering** - By JLPT level, item type, pagination (limit/offset)

**Phase 7: Flashcard CLI - Review Session** - ‚úÖ COMPLETE (2025-10-26)

### Completed:
- ‚úÖ UI components (ui/display.py) - 4 new functions for review session
- ‚úÖ Review command (cli/flashcard.py) - Interactive session with FSRS
- ‚úÖ Rating prompts (1-4) with validation
- ‚úÖ Session summary with statistics (accuracy, time, next reviews)
- ‚úÖ Comprehensive test suite (tests/test_review_session.py) - 19 tests
- ‚úÖ All tests passing (387 total tests)
- ‚úÖ 82% overall project coverage, 98% on new UI code
- ‚úÖ Manual end-to-end testing verified

### Review Commands Available:
```bash
japanese-cli flashcard review                    # Review all due cards
japanese-cli flashcard review --limit 10        # Review max 10 cards
japanese-cli flashcard review --level n5        # Review N5 cards only
japanese-cli flashcard review --type vocab      # Review vocabulary only
```

### Key Features:
- **Question ‚Üí Answer flow** - Vietnamese meaning ‚Üí Japanese word (production practice)
- **Rich UI** - Beautiful panels, tables, color-coded JLPT levels
- **FSRS integration** - Automatic state updates and interval calculations
- **Time tracking** - Millisecond precision for each card and total session
- **Review history** - All reviews recorded in database with rating and duration
- **Progress feedback** - Clear indication of current position (Card 5/20)
- **Early exit** - Ctrl+C saves all reviewed cards and exits cleanly

**Phase 8: Progress Tracking** - ‚úÖ COMPLETE (2025-10-26)

### Completed:
- ‚úÖ Statistics calculation module (srs/statistics.py) - 499 lines, 9 functions
- ‚úÖ Database query extensions (queries.py) - `update_progress_level()`
- ‚úÖ UI display components (ui/display.py) - 3 new functions (~305 lines)
  - `display_progress_dashboard()` - Real-time statistics panel
  - `display_statistics()` - Detailed analytics with bar charts
  - `format_relative_date()` - Human-readable dates
- ‚úÖ CLI progress commands (cli/progress.py) - 273 lines, 3 commands
- ‚úÖ All commands manually tested and verified working
- ‚úÖ Progress model bug fixes (NULL milestones handling)

### Progress Commands Available:
```bash
japanese-cli progress show          # Dashboard with real-time stats
japanese-cli progress set-level n4  # Update target JLPT level
japanese-cli progress set-level n4 --current  # Update current level
japanese-cli progress stats         # All-time detailed statistics
japanese-cli progress stats --range 7d   # Last 7 days stats
japanese-cli progress stats --range 30d  # Last 30 days stats
```

### Key Features:
- **Real-time Statistics** - All data calculated on-demand from database
- **JLPT Level Management** - Easy switching between current/target levels
- **Visual Progress Indicators** - Emojis, colors, ASCII bar charts
- **Study Streak Tracking** - With üî• indicator for 7+ day streaks
- **Mastery Tracking** - Based on FSRS stability threshold (21 days)
- **Retention Rate** - Color-coded (green ‚â•85%, yellow ‚â•70%, red <70%)
- **Time-based Filtering** - Stats for 7d/30d/all-time periods
- **Most Reviewed Items** - Track which cards need attention
- **Daily Activity Visualization** - ASCII bar charts for review patterns

### Statistics Module Functions:
- `calculate_vocab_counts_by_level()` - Count vocabulary by JLPT level
- `calculate_kanji_counts_by_level()` - Count kanji by JLPT level
- `calculate_mastered_items()` - Items with stability ‚â• 21 days
- `calculate_retention_rate()` - (Good + Easy) / Total √ó 100%
- `calculate_average_review_duration()` - Average time per card
- `aggregate_daily_review_counts()` - Reviews grouped by date
- `get_most_reviewed_items()` - Top N items by review count
- `get_reviews_by_date_range()` - Filter reviews by date

### Integration Testing Results:
‚úÖ All three commands tested and working:
- `progress show` - Displays accurate statistics (620 vocab, 103 kanji, 100% retention)
- `progress set-level n4` - Successfully updates target level
- `progress stats --range all` - Shows summary, daily activity, top items

**Phase 9: Grammar Points** - ‚úÖ COMPLETE (2025-10-26)

### Completed:
- ‚úÖ CLI grammar commands (cli/grammar.py) - 252 lines, 4 commands (add, list, show, edit)
- ‚úÖ Grammar UI components - 345 lines added to ui/prompts.py and ui/display.py
  - `prompt_grammar_data()` - Interactive grammar data collection with validation
  - `prompt_example_data()` - Collect individual examples (JP, VI, EN)
  - `format_grammar_table()` - Rich table with ID, Title, Structure, JLPT, Examples
  - `format_grammar_panel()` - Detailed panel with all grammar information
- ‚úÖ Comprehensive test suite - 22 tests (21 passing, 1 skipped for edge case)
- ‚úÖ Integration with existing system verified
- ‚úÖ Total project tests: **409 passing**

### Grammar Commands Available:
```bash
japanese-cli grammar add                    # Interactive grammar point creation
japanese-cli grammar list                   # List all grammar points
japanese-cli grammar list --level n5        # Filter by JLPT level
japanese-cli grammar show 1                 # Show detailed grammar point
japanese-cli grammar edit 1                 # Edit existing grammar point
```

### Key Features:
- Minimum 1 example required (recommended 3)
- JLPT level color-coding (n5=green, n4=cyan, n3=yellow, n2=magenta, n1=red)
- Vietnamese-first design (Vietnamese translation required)
- Optional English translations
- Related grammar cross-references support
- Pydantic validation at input time
- Rich formatting with proper Japanese character display

### Integration Testing Results:
‚úÖ All four commands tested and working:
- `grammar add` - Successfully creates grammar points with examples
- `grammar list` - Displays table with filtering by JLPT level
- `grammar show 1` - Shows detailed panel with examples and Vietnamese/English translations
- `grammar edit 1` - Pre-fills values for editing

**Next Phase**: Phase 10 - Polish & Testing
- Fix edge case bug (infinite loop in prompt_grammar_data)
- Improve error handling across all modules
- Add integration tests for CLI workflows
- Performance testing with large datasets
- Documentation updates (README, troubleshooting)

**Last Updated**: 2025-10-26
**Current Status**: Phase 9 Complete - Full grammar management functional
